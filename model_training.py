# -*- coding: utf-8 -*-
"""Startup Dashboard/

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkHqAJr6opHq0TmTVSqNIkLGqn4iYNE_
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

pd.set_option('display.max_columns',None)
pd.set_option('display.max_rows',100)
sns.set(style='whitegrid')

df=pd.read_csv('startup_clean.csv')

df.info()

df.head(4)

# Convert date column
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# Extract useful date features
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['quarter'] = df['date'].dt.quarter

# Standardize text columns
text_cols = ['startup', 'vertical', 'subvertical', 'city', 'Investor', 'Type']
for col in text_cols:
    df[col] = df[col].astype(str).str.strip().str.lower()

print("✅ Basic cleaning done.")
df.sample(5)

def normalize_text(text):
    text = str(text).lower().strip()                     # lowercase + remove extra spaces
    text = text.replace('.', '').replace(',', '')        # remove punctuation
    text = text.replace("’", "").replace("'", "")        # remove apostrophes
    text = text.replace("&", "and")                      # standardize symbols
    text = text.replace(" capital partners", " capital") # remove common suffix variations
    return text

df['startup'] = df['startup'].apply(normalize_text)
df['Investor'] = df['Investor'].apply(normalize_text)

print('cleaned')

!pip install fuzzywuzzy python-Levenshtein --quiet
from fuzzywuzzy import process

from fuzzywuzzy import process

def fuzzy_grouping_fast(unique_names, threshold=90):
    mapping = {}
    unique_names = list(unique_names)
    processed = set()

    for name in unique_names:
        if name in processed:
            continue

        # Only compare with names starting with the same first letter
        subset = [n for n in unique_names if n[0] == name[0]]
        matches = process.extract(name, subset, limit=None)
        similar = [match for match, score in matches if score >= threshold]

        for s in similar:
            mapping[s] = name
            processed.add(s)
    return mapping

unique_investors = df['Investor'].dropna().unique()
investor_map = fuzzy_grouping_fast(unique_investors, threshold=90)
df['Investor'] = df['Investor'].map(investor_map).fillna(df['Investor'])

unique_startups = df['startup'].dropna().unique()
startup_map = fuzzy_grouping_fast(unique_startups, threshold=92)
df['startup'] = df['startup'].map(startup_map).fillna(df['startup'])

# Export for review
df[['Investor']].drop_duplicates().to_csv('unique_investors.csv', index=False)
df[['startup']].drop_duplicates().to_csv('unique_startups.csv', index=False)

df1=pd.read_csv('unique_investors.csv')
df2=pd.read_csv('unique_startups.csv')

df1.info()

df2.sample(5)

df.head(5)

df['amount']=df['amount'].astype(str)+'Cr'

df.head(2)

df.drop_duplicates().to_csv('data.csv',index=False)

import kagglehub

# Download latest version
path = kagglehub.dataset_download("akhilkumarkummari/performance-of-indian-startups")

print("Path to dataset files:", path)



! ls /root/.cache/kagglehub/datasets/akhilkumarkummari/performance-of-indian-startups/versions/1

!cp "/root/.cache/kagglehub/datasets/akhilkumarkummari/performance-of-indian-startups/versions/1/Indian Startup.csv" ./performance.csv

! pip install ydata-profiling

import pandas as pd
from ydata_profiling import ProfileReport

df=pd.read_csv('performance.csv')

profile=ProfileReport(df,title='Startup Performance Profiling Report',explorative=True)

profile.to_notebook_iframe()

profile.to_file('startup_performance_report.html')

df.head(3)

"""## Proceeding with the ml part

"""

df2=pd.read_csv('data.csv')

df2.head(5)

df.head(5)

import pandas as pd

df1=pd.read_csv('startup_clean.csv')

df1.head()

df1['date'] = pd.to_datetime(df1['date'], errors='coerce')

df1['year']=df1['date'].dt.year

df1.info()

df1.info()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import r2_score, mean_absolute_error
import joblib

agg = df1.groupby('startup').agg({
    'amount_num': ['sum', 'mean', 'count'],
    'year': ['min', 'max', 'nunique'],
    'Investor': 'nunique',
    'vertical': 'first',
    'city': 'first'
}).reset_index()

agg.columns = [
    'startup', 'total_investment', 'avg_investment', 'rounds',
    'first_year', 'last_year', 'active_years', 'unique_investors',
    'sector', 'city'
]

agg['funding_velocity'] = agg['total_investment'] / (agg['active_years'] + 1)
agg['investor_density'] = agg['unique_investors'] / (agg['rounds'] + 1)
agg['funding_stability'] = agg['avg_investment'] / (agg['total_investment'] + 1)
agg.fillna(0, inplace=True)

scaler = MinMaxScaler()
agg[['inv_sum_norm', 'velocity_norm', 'density_norm']] = scaler.fit_transform(
    agg[['total_investment', 'funding_velocity', 'investor_density']])

agg['performance_score'] = (
    0.5 * agg['inv_sum_norm'] +
    0.3 * agg['velocity_norm'] +
    0.2 * agg['density_norm']
)

le_sector = LabelEncoder()
le_city = LabelEncoder()
agg['sector_encoded'] = le_sector.fit_transform(agg['sector'].astype(str))
agg['city_encoded'] = le_city.fit_transform(agg['city'].astype(str))

X = agg[['total_investment', 'avg_investment', 'rounds', 'active_years',
         'unique_investors', 'funding_velocity', 'investor_density',
         'funding_stability', 'sector_encoded', 'city_encoded']]
y = agg['performance_score']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

# --- 8. Evaluation ---
y_pred = model.predict(X_test)
print("Model Evaluation")
print(f"R² Score: {r2_score(y_test, y_pred):.3f}")
print(f"Mean Absolute Error: {mean_absolute_error(y_test, y_pred):.3f}")

joblib.dump(model, "investment_model.pkl")
joblib.dump(le_sector, "sector_encoder.pkl")
joblib.dump(le_city, "city_encoder.pkl")
print("✅ Model saved as investment_model.pkl")